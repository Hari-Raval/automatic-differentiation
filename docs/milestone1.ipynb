{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*text here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Chain Rule \n",
    "\n",
    "At the heart of automatic differentiation is the Chain Rule that enables us to decompose a complex derivative into a set of derivatives involving elementary functions of which we know explicit forms. \n",
    "\n",
    "We will first introduce the case of 1-D input and generalize it to multidimensional inputs.\n",
    "\n",
    "1-D input: Suppose we have a function $ h(u(t)) $ and we want to compute the derivative of $ h $ with respect to $ t $. This derivative is given by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dh}{dt} = \\frac{\\partial h}{\\partial u} \\frac{du}{dt}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Before introducing vector inputs, let's first take a look at the gradient operator $ \\nabla $\n",
    "\n",
    "That is, for  $ y\\colon \\mathbb {R} ^{n} \\to \\mathbb {R} $, its gradient $ \\nabla y \\colon \\mathbb {R} ^{n} \\to \\mathbb {R} ^{n}$ is defined at the point $ x = (x_1, ..., x_n) $ in n-dimensional space as the vector\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla y(x) =\n",
    "\\begin{bmatrix}\n",
    "{\\frac {\\partial y}{\\partial x_{1}}}(x)\n",
    "\\\\\n",
    "\\vdots \n",
    "\\\\\n",
    "{\\frac {\\partial y}{\\partial x_{n}}}(x)\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Multidimensional (or Vector) inputs: Suppose we have a function $ h(y_1(x), ..., y_n(x)) $ and we want to compute the derivative of $ h $ with respect to $ x $. This derivative is given by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla h_x = \\sum_{i=1}^n \\frac{\\partial h}{\\partial y_i} \\nabla y_i(x)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Part 2: Evaluation (Forward) Trace\n",
    "Definition: Suppose x = $ \\begin{bmatrix} {x_1} \\\\ \\vdots \\\\ {x_m} \\end{bmatrix} $, we defined $ v_{k - m} = x_k $ for $ k = 1, 2, ..., m $ in the evaluation trace.\n",
    "\n",
    "Motivation: The evaluation trace introduces intermediate results $ v_{k-m} $ of elementary unary or binary operations. \n",
    "\n",
    "#### Part 3: Computation (Forward) Graph\n",
    "\n",
    "We have associated each $ v_{k-m} $ to a node in a graph for a visualization of the partial ordering.\n",
    "\n",
    "#### Part 4: Computing the derivative\n",
    "\n",
    "Let's return to the gradient $ \\nabla $\n",
    "\n",
    "Definition of gradient operator: we project the gradient from before in the direction of $ p $\n",
    "\n",
    "$$ D_p v_j = (\\nabla v_j)^T p = (\\sum_{i < j} \\frac{\\partial{v_j}} {\\partial{v_i}} \\nabla v_i)^T p = \\sum_{i < j} \\frac{\\partial{v_j}} {\\partial{v_i}} (\\nabla v_i)^T p = \\sum_{i < j} \\frac{\\partial{v_j}} {\\partial{v_i}} D_p v_i$$ \n",
    "\n",
    "Higher dimension: We recursively apply the same technic introduced above to each entry of the vector valued function f\n",
    "\n",
    "Two take away messages: \n",
    "\n",
    "1) We can compute the derivative of $ v_j $ with knowledge of $ v_i $ and $ D_p v_i $ for $ i < j $.\n",
    "\n",
    "2) Once a child node is evaluated, its parent node(s) are no longer needed. There is no need to store the full graph of and pairs.\n",
    "\n",
    "#### Part 5: Dual Number\n",
    "\n",
    "Definition: we define a dual number $ z_j = v_j + D_p v_j \\epsilon $ such that $ \\epsilon^2 = 0 $ where $ v_j $ corresponds to primal trace and $ D_p v_j $ corresponds to tangent trace. \n",
    "\n",
    "$ f(z_j) = f(v_j + D_p v_j \\epsilon) = f(v_j) + f'(v_j) D_p v_j \\epsilon $ using a Taylor series expansion\n",
    "\n",
    "All higher term vanish because of the definition $ \\epsilon^2 = 0 $\n",
    "\n",
    "Advantage: Operations on Dual Number pertain the form of Taylor expansion.\n",
    "\n",
    "Consider the following example\n",
    "$$\n",
    "\\begin{align}\n",
    "z_1 &= a_1 + b_1 \\epsilon \\\\ \n",
    "z_2 &= a_2 + b_2 \\epsilon \\\\\n",
    "z_1 + z_2 &= (a_1 + a_2) + (b_1 + b_2) \\epsilon \\\\\n",
    "z_1 z_2 &= a_1 a_2 + (a_1 b_2 + a_2 b_1) \\epsilon \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We subsititute $ a_1 = u, b_1 = u' $ and $ a_2 = v $ and $ b_2 = v' $,\n",
    "$$\n",
    "\\begin{align}\n",
    "z_1 + z_2 &= (u + v) + (u' + v') \\epsilon \\\\\n",
    "z_1 z_2 &= u v + (u v' + u' v) \\epsilon \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use $\\textit{PackageName}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*text here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*text here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*text here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Licensing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*text here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
